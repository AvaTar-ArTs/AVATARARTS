# NoteBookLLM Startup Guide

## Requirements

- **Python**: 3.10+
- **Node.js**: 18+
- **npm**: 9+
- **FFmpeg**: Optional, for audio processing

---

## Quick Start

### Step 1: Set Environment Variables

```bash
# Copy the environment template
copy .env.example backend\.env
```

Edit `backend\.env` and fill in your API keys:

```env
# Choose AI Provider (gemini / openai / anthropic / ollama / groq / deepseek)
AI_PROVIDER=gemini

# ===== Gemini Settings =====
GEMINI_API_KEY=your-Gemini-API-Key
GEMINI_MODEL=gemini-2.0-flash
GEMINI_IMAGE_MODEL=gemini-2.0-flash-exp-image-generation

# ===== OpenAI Settings =====
OPENAI_API_KEY=your-OpenAI-API-Key
OPENAI_MODEL=gpt-5.1
OPENAI_IMAGE_MODEL=dall-e-3

# ===== Anthropic Settings =====
ANTHROPIC_API_KEY=your-Anthropic-API-Key
ANTHROPIC_MODEL=claude-sonnet-4-20250514

# ===== Ollama Settings (local model) =====
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# ===== Groq Settings (fast inference) =====
GROQ_API_KEY=your-Groq-API-Key
GROQ_MODEL=llama-3.3-70b-versatile

# ===== DeepSeek Settings (reasoning model) =====
DEEPSEEK_API_KEY=your-DeepSeek-API-Key
DEEPSEEK_MODEL=deepseek-chat
DEEPSEEK_REASONER_MODEL=deepseek-reasoner
```

**Get API Keys:**
- Gemini: https://aistudio.google.com/app/apikey
- OpenAI: https://platform.openai.com/api-keys
- Anthropic: https://console.anthropic.com/settings/keys
- Ollama: https://ollama.ai/download (local install, no API key)
- Groq: https://console.groq.com/keys
- DeepSeek: https://platform.deepseek.com/api_keys

---

### Step 2: Create a Virtual Environment and Install Backend Dependencies

> **Important:** Use a virtual environment to avoid package conflicts with other Python projects.

```bash
cd backend

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# macOS/Linux:
# source venv/bin/activate

# When activated, your prompt shows (venv)

# Install dependencies
pip install -r requirements.txt
```

**Note:** Every time you open a new terminal window, activate the virtual environment first:

```bash
cd backend
venv\Scripts\activate   # Windows
# source venv/bin/activate  # macOS/Linux
```

**Optional dependency (audio processing):**

#### Install FFmpeg on Windows

1. Go to https://github.com/BtbN/FFmpeg-Builds/releases
2. Download `ffmpeg-master-latest-win64-gpl.zip`
3. Extract to `C:\ffmpeg` (or another location)
4. Add FFmpeg to your system PATH:
   - Press `Win + R`, type `sysdm.cpl`, press Enter
   - Click the "Advanced" tab -> "Environment Variables"
   - Under "System variables", select `Path` and click "Edit"
   - Click "New" and enter `C:\ffmpeg\bin`
   - Click "OK" to save
5. Open a new Command Prompt and run `ffmpeg -version` to verify

#### Install FFmpeg on macOS

```bash
brew install ffmpeg
```

#### Install FFmpeg on Linux

```bash
sudo apt install ffmpeg
```

#### Local Whisper (offline speech-to-text) - Optional

> **Most users do not need this.** Use online services (Groq Whisper or OpenAI Whisper API).
>
> Only install this if you need **fully offline** speech-to-text. It downloads about **3GB** (includes PyTorch).

```bash
# Install only if you need offline functionality
pip install openai-whisper
```

---

### Step 3: Start the Backend Server

```bash
cd backend

# Ensure the virtual environment is active (should show (venv))
venv\Scripts\activate   # Windows
# source venv/bin/activate  # macOS/Linux

# Start server
python app.py
```

The backend runs at **http://localhost:5000**

---

### Step 4: Install Frontend Dependencies

Open a **new terminal window** (frontend uses npm, no Python venv required):

```bash
cd frontend
npm install
npm install -D @tailwindcss/typography
```

---

### Step 5: Start the Frontend Dev Server

```bash
cd frontend
npm run dev
```

The frontend runs at **http://localhost:3000**

---

## How to Use

1. Open `http://localhost:3000` in your browser
2. Click "New Folder" to organize notebooks
3. Click "New Notebook" to create your first notebook
4. Drag notebooks into folders to organize them
5. Add sources on the left panel (upload files, audio, paste URLs, YouTube links, or text)
6. Chat with AI in the middle panel; answers are grounded on your sources
7. Use the Studio panel on the right to generate summaries, mind maps, flashcards, quizzes, podcasts, and more

### Folder Management Features

- **Create folders**: custom names and emoji icons
- **Drag & drop**: move notebooks between folders
- **Expand/collapse**: click the folder title to toggle
- **Edit/delete**: rename or delete (notebooks move to Unsorted)

---

## AI Providers

| Provider | Highlights | Embeddings | Image Gen | Requires API Key |
|----------|------------|:----------:|:---------:|:---------------:|
| **Gemini** | Google multimodal model | âœ… | âœ… | Yes |
| **OpenAI** | GPT-4.1/5.1 + DALL-E 3 | âœ… | âœ… | Yes |
| **Anthropic** | Claude Opus/Sonnet long context | âŒ* | âŒ | Yes |
| **Ollama** | Local model, unlimited use | âœ… | âŒ | No |
| **Groq** | Ultra-fast inference | âŒ* | âŒ | Yes |
| **DeepSeek** | R1 reasoning model | âŒ* | âŒ | Yes |

> *Providers without embeddings will automatically fall back to a backup provider (Gemini/OpenAI/Ollama).

---

## Project Structure

```
open-notebookllm/
â”œâ”€â”€ backend/                    # Flask backend (Python)
â”‚   â”œâ”€â”€ app.py                 # App entry
â”‚   â”œâ”€â”€ config.py              # Configuration
â”‚   â”œâ”€â”€ requirements.txt       # Python dependencies
â”‚   â”œâ”€â”€ models/                # Database models
â”‚   â”œâ”€â”€ services/              # Business logic services
â”‚   â”‚   â”œâ”€â”€ ai_providers/      # AI provider abstraction
â”‚   â”‚   â”‚   â”œâ”€â”€ gemini_provider.py
â”‚   â”‚   â”‚   â”œâ”€â”€ openai_provider.py
â”‚   â”‚   â”‚   â”œâ”€â”€ anthropic_provider.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ollama_provider.py
â”‚   â”‚   â”‚   â”œâ”€â”€ groq_provider.py
â”‚   â”‚   â”‚   â””â”€â”€ deepseek_provider.py
â”‚   â”‚   â”œâ”€â”€ ai_service_manager.py  # AI service manager
â”‚   â”‚   â”œâ”€â”€ rag_service.py     # RAG retrieval
â”‚   â”‚   â”œâ”€â”€ search_service.py  # Full-text search (FTS5)
â”‚   â”‚   â”œâ”€â”€ audio_service.py   # STT/TTS
â”‚   â”‚   â”œâ”€â”€ podcast_service.py # Podcast generation
â”‚   â”‚   â”œâ”€â”€ youtube_service.py # YouTube processing
â”‚   â”‚   â”œâ”€â”€ web_scraper_service.py  # Web scraping
â”‚   â”‚   â”œâ”€â”€ file_parser_service.py  # File parsing
â”‚   â”‚   â””â”€â”€ studio_service.py  # Studio output generation
â”‚   â””â”€â”€ controllers/           # API controllers
â”‚
â”œâ”€â”€ frontend/                   # React frontend (TypeScript)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ pages/             # Page components
â”‚   â”‚   â”œâ”€â”€ components/        # UI components
â”‚   â”‚   â”œâ”€â”€ store/             # Zustand state
â”‚   â”‚   â”œâ”€â”€ api/               # API client
â”‚   â”‚   â””â”€â”€ types/             # TypeScript types
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.ts
â”‚
â”œâ”€â”€ uploads/                    # Uploaded file storage
â”œâ”€â”€ .env.example               # Environment template
â””â”€â”€ å•Ÿå‹•æŒ‡å—.md                 # This file
```

---

## API Endpoints

| Module | Endpoint | Method | Description |
|--------|----------|--------|-------------|
| **Notebooks** | `/api/notebooks` | GET | List notebooks |
| | `/api/notebooks` | POST | Create notebook |
| | `/api/notebooks/:id` | GET | Get notebook |
| | `/api/notebooks/:id` | DELETE | Delete notebook |
| **Folders** | `/api/folders` | GET | List folders |
| | `/api/folders` | POST | Create folder |
| | `/api/folders/:id` | PUT | Update folder |
| | `/api/folders/:id` | DELETE | Delete folder |
| | `/api/folders/with-notebooks` | GET | Get folders and notebooks |
| | `/api/folders/:id/notebooks/:notebookId` | PUT | Add notebook to folder |
| **Sources** | `/api/notebooks/:id/sources` | GET | List sources |
| | `/api/notebooks/:id/sources/upload` | POST | Upload file/audio |
| | `/api/notebooks/:id/sources/url` | POST | Add URL |
| | `/api/notebooks/:id/sources/youtube` | POST | Add YouTube |
| | `/api/notebooks/:id/sources/text` | POST | Add text |
| | `/api/notebooks/:id/search` | POST | Search source content |
| | `/api/sources/reindex` | POST | Rebuild search index |
| **Chats** | `/api/notebooks/:id/chats` | GET | Get chat history |
| | `/api/notebooks/:id/chats/stream` | POST | Stream chat (SSE) |
| | `/api/notebooks/:id/suggested-questions` | GET | Suggested questions |
| **Studio** | `/api/notebooks/:id/studio/summary` | POST | Generate summary |
| | `/api/notebooks/:id/studio/mindmap` | POST | Generate mind map |
| | `/api/notebooks/:id/studio/flowchart` | POST | Generate flowchart (Draw.io) |
| | `/api/notebooks/:id/studio/diagram` | POST | Generate architecture diagram (Draw.io) |
| | `/api/notebooks/:id/studio/flashcards` | POST | Generate flashcards |
| | `/api/notebooks/:id/studio/quiz` | POST | Generate quiz |
| | `/api/notebooks/:id/studio/report` | POST | Generate report |
| | `/api/notebooks/:id/studio/presentation` | POST | Generate slides (with images) |
| | `/api/notebooks/:id/studio/infographic` | POST | Generate infographic (with images) |
| | `/api/notebooks/:id/studio/podcast` | POST | Generate podcast |
| | `/api/notebooks/:id/studio/podcast/script` | POST | Generate podcast script only |
| | `/api/notebooks/:id/studio/podcast/audio` | POST | Generate audio from script |
| | `/api/notebooks/:id/studio/podcast/voices` | GET | List available voices |
| | `/api/notebooks/:id/studio/tts` | POST | Text-to-speech |
| **Settings** | `/api/settings` | GET | Get settings |
| | `/api/settings` | PUT | Update settings |
| | `/api/settings/providers` | GET | List available providers |
| | `/api/settings/models/:provider` | GET | List provider models |
| | `/api/settings/test-api` | POST | Test API connection |

---

## Supported Source Types

| Type | Description | File Types |
|------|-------------|------------|
| PDF | PDF documents | `.pdf` |
| Text | Plain text files | `.txt`, `.md` |
| Word | Word documents | `.docx`, `.doc` |
| Excel | Spreadsheets | `.xlsx`, `.xls`, `.csv` |
| Web | Web links | URL |
| YouTube | YouTube captions/transcripts | YouTube URL |
| **Audio** | Speech-to-text (STT) | `.mp3`, `.wav`, `.m4a`, `.ogg`, `.flac`, `.webm` |

### Audio Processing (STT)

Supported speech-to-text providers:

| Provider | Type | Advantages | Requires |
|----------|------|------------|----------|
| **OpenAI Whisper** | Online | High quality, multilingual | OpenAI API Key |
| **Groq Whisper** | Online | Ultra-fast, free quota | Groq API Key |
| **Local Whisper** | Offline | Fully offline | Install 3GB package |

#### How to Use

1. Click "Add Source" in the left "Sources" panel
2. Select the "Audio" tab
3. Choose an STT provider (**Groq Whisper recommended**, free and fast)
4. Select language
5. Upload audio

#### Recommended Options

- **Groq Whisper** (recommended): free quota, ultra-fast. Get API Key: https://console.groq.com/keys
- **OpenAI Whisper**: high quality, requires OpenAI API Key
- **Local Whisper**: requires ~3GB download (PyTorch, etc.), only for offline use

> **Tip:** Most users only need online services; local Whisper is optional.

---

## Studio Output Types

| Type | Description | Key Features |
|------|-------------|-------------|
| Audio Summary | Spoken summary of source content | - |
| Video Summary | Video summary of source content | - |
| Mind Map | Mermaid visualization | Export SVG, zoom control |
| Flowchart | Draw.io flowchart | ðŸ†• AI generation, editable, SVG export |
| Architecture | Draw.io architecture diagram | ðŸ†• 6 chart types, system visualization |
| Report | Structured report | - |
| Flashcard | Q&A flashcards | ðŸ†• Bloom taxonomy, difficulty levels |
| Quiz | Multi-format quiz | ðŸ†• 5 question types, difficulty levels |
| Infographic | Chart.js visualization | ðŸ†• 7 chart types |
| Slides | Slide outline + per-slide images | âœ… AI images, PPTX export |
| Table | Structured tables | - |
| **Podcast** | Multi-speaker podcast (1-4 people) | Multiple styles, TTS voices |

### ðŸ†• Flashcard/Quiz Difficulty Levels

When generating flashcards and quizzes, you can choose difficulty:

| Level | Bloom's Tier | Description |
|-------|--------------|-------------|
| Easy | Remember, Understand | Basic definitions, recall |
| Medium | Apply, Analyze | Application, comparison, analysis |
| Hard | Evaluate, Create | Critical thinking, problem solving |
| Mixed | All tiers | Progressive mix of difficulties |

### ðŸ†• Quiz Question Types

| Type | Description |
|------|-------------|
| Multiple Choice | Single-choice A/B/C/D options |
| True/False | Correct/Incorrect |
| Fill in the Blank | Provide the correct answer |
| Matching | Match left and right items |
| Short Answer | Open-ended response |

### ðŸ†• Infographic (Chart.js)

Auto-selects the most suitable chart type:

| Chart Type | Use Case |
|------------|----------|
| Bar | Category comparison |
| Line | Trend analysis |
| Pie | Proportion distribution |
| Doughnut | Proportion distribution (variant) |
| Radar | Multi-dimensional comparison |
| Scatter | Correlation analysis |
| PolarArea | Category comparison (variant) |

### ðŸ†• Draw.io Flowcharts/Architecture

Uses the embedded react-drawio editor with live editing and export:

| Diagram Type | Description |
|--------------|-------------|
| architecture | System architecture, component relationships |
| sequence | Interaction sequence, message flow |
| class | OOP structure, inheritance |
| er | ERD, database relationships |
| network | Network topology, device connections |
| auto | Auto-select based on content |

**Key features:**
- AI-generated Draw.io XML
- Live browser editing
- SVG export
- Copy raw XML

### Podcast Generation

Supports multi-speaker podcasts:
- **Speakers**: 1-4
- **Style**: casual chat, educational, debate, interview
- **Duration**: 5/10/15/20 minutes
- **Audio**: optional TTS from script

### Image Generation

Slides and infographics support AI-generated images:

- **Gemini**: `gemini-2.0-flash-exp-image-generation` multimodal model (standard API key)
- **OpenAI**: `dall-e-3` image model

> **Note:** Gemini uses a multimodal model (not Imagen), so standard API keys work.

---

## Search

Three search modes are available:

| Mode | Description | Strengths |
|------|-------------|-----------|
| **Full-text** | SQLite FTS5 index | Fast, precise keyword match |
| **Vector** | Semantic similarity | Understands meaning, finds related content |
| **Hybrid** | Full-text + vector | Best results, recommended |

### ðŸ†• Advanced RAG Search Techniques

| Technique | Description |
|-----------|-------------|
| **RRF Fusion** | Reciprocal Rank Fusion combining full-text + vector rankings |
| **Query Expansion** | LLM expands intent with semantic variants |
| **LLM Reranking** | LLM reorders results intelligently |
| **Deduplication** | Automatically merges duplicate results |

---

## FAQs

### Q: Backend shows ModuleNotFoundError at startup?
**A:** Ensure you ran `pip install -r requirements.txt` inside the virtual environment.

### Q: Dependency conflicts during install?
**A:** Your Python environment likely has conflicting packages. Fix by:
1. Create a new virtual environment:
   ```bash
   cd backend
   python -m venv venv
   venv\Scripts\activate   # Windows
   pip install -r requirements.txt
   ```
2. Always run inside the virtual environment

### Q: Frontend cannot connect to backend?
**A:**
1. Ensure the backend is running at `http://localhost:5000`
2. Check the proxy settings in `vite.config.ts`

### Q: API Key is invalid?
**A:**
1. Ensure `.env` is in the `backend/` directory
2. Verify the API key is correct and active
3. Use "Test Connection" in the settings page

### Q: File upload failed?
**A:**
1. Ensure `uploads/` exists and is writable
2. File size limit is 50MB

### Q: Audio transcription failed?
**A:**
1. Ensure FFmpeg is installed (format conversion)
2. Audio size limit is 25MB
3. Try a different STT provider

### Q: Ollama cannot connect?
**A:**
1. Ensure Ollama is running: `ollama serve`
2. Ensure the model is pulled: `ollama pull llama3.2`
3. Verify `OLLAMA_BASE_URL` is correct

---

## Tech Stack

| Layer | Technology |
|------|------------|
| Backend | Flask 3.0 |
| Database | SQLite + SQLAlchemy + FTS5 |
| Frontend | React 18 + TypeScript |
| Build tool | Vite |
| Styling | TailwindCSS |
| State mgmt | Zustand |
| Chart rendering | Chart.js + react-chartjs-2 |
| Mind map rendering | Mermaid.js |
| Flowchart/Architecture | Draw.io + react-drawio |
| AI Text API | Gemini / OpenAI / Anthropic / Ollama / Groq / DeepSeek |
| AI Image API | Gemini multimodal / DALL-E 3 |
| Speech-to-text | OpenAI Whisper / Groq Whisper / Local Whisper |
| Text-to-speech | OpenAI TTS / Google Cloud TTS |

---

## Development Commands

```bash
# Backend dev mode (auto-reload)
cd backend
flask run --debug

# Frontend dev mode
cd frontend
npm run dev

# Frontend production build
cd frontend
npm run build

# Frontend production preview
cd frontend
npm run preview
```

---

## License

This project is for learning and personal use only.
